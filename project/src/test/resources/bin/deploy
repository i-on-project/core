#!/bin/sh

set -eu

# Check for needed evvars
if [ -z "$GCP_KEY" ] ||\
  [ -z "$GCP_REPO" ] ||\
  [ -z "$GCP_PROJECT_ID" ] ||\
  [ -z "$GCP_ACCOUNT" ] ||\
  [ -z "$GCP_ZONE" ] ||\
  [ -z "$GCP_INSTANCE" ] ||\
  [ -z "$GCP_DB_INSTANCE" ] ||\
  [ -z "$DB_CON_STRING_SUFFIX" ] ||\
  [ -z "$DEV_DB_CON_STRING_SUFFIX" ]; then
  printf "You need to set the following environment variables:\n\t%s\n\t%s\n\t%s\n\t%s\n\t%s\n\t%s\n\t%s\n\t%s\n\t%s\n" \
    "GCP_KEY" \
    "GCP_REPO" \
    "GCP_ZONE" \
    "GCP_PROJECT_ID" \
    "GCP_ACCOUNT" \
    "GCP_INSTANCE" \
    "GCP_DB_INSTANCE" \
    "DB_CON_STRING_SUFFIX" \
    "DEV_DB_CON_STRING_SUFFIX"
  exit 1
fi

# A file with the GCP credentials is placed in a foreign machine
# Erase every trace of the file in the HDD by filling the sectors with random data
# DIY version of the `shred` command
wipe_file() {
  dd if=/dev/urandom of="$1" bs="$2" count="$3"
  dd if=/dev/urandom of="$1" bs="$2" count="$3"
  dd if=/dev/urandom of="$1" bs="$2" count="$3"
  dd if=/dev/urandom of="$1" bs="$2" count="$3"
  dd if=/dev/zero of="$1" bs="$2" count="$3"
  rm "$1"
}

# Will authenticate this environment with the GCP account
# Configures docker to use GCP account for pushing images to the GCR
auth_gcp() {
  key_file="/tmp/key.json"
  auth_gcp_clean() {
    # completely wipe the credentials file from the disk
    if [ -f "$key_file" ]; then
      printf "Wiping key file.\n"
      key_file_size="$(du -k "$key_file" | awk '{print $1}')"
      wipe_bs="1K"
      wipe_file "$key_file" "$wipe_bs" "$key_file_size"
    fi
  }
  trap 'auth_gcp_clean' EXIT
  printf "%s\n" "$GCP_KEY" > "$key_file"
  
  gcloud auth activate-service-account "$GCP_ACCOUNT" --key-file="$key_file"
  gcloud config set project "$GCP_PROJECT_ID"
  printf "gcloud authenticated.\n"

  # Docker config
  echo "$GCP_KEY" | docker login -u _json_key --password-stdin "https://${GCP_REPO}"
  printf "Docker authenticated.\n"
  auth_gcp_clean
}

# Make an attempt to migrate the database's schema
schema_migration() {
  printf "Attempting to migrate DB schema...\n"
  db_proxy_port="10025"
  schema_diff_img="core-db-schema-diff"
  db_con_string_prefix="postgresql://localhost:$db_proxy_port"
  db_con_string="${db_con_string_prefix}/${DB_CON_STRING_SUFFIX}"
  dev_db_con_string="${db_con_string_prefix}/${DEV_DB_CON_STRING_SUFFIX}"

  wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O /tmp/cloud_sql_proxy
  chmod +x /tmp/cloud_sql_proxy
  /tmp/cloud_sql_proxy -instances="$GCP_DB_INSTANCE=tcp:$db_proxy_port" &

  backup_dir="$(pwd)"
  cd .docker/src/res/bin/schema_diff
  # TODO: Copy the sql scripts to the docker image on build time (i.e. don't use a mount point)
  docker build -t "$schema_diff_img" .
  docker run --rm --network="host" \
    -e DEV_DB_URL="$dev_db_con_string" \
    -e DB_URL="$db_con_string" \
    -v "$(pwd)/../../docker:/mnt" \
    "$schema_diff_img" apply
  cd "$backup_dir"

  pkill cloud_sql_proxy || true
  rm /tmp/cloud_sql_proxy
  printf "Schema migrated successfully.\n"
}

# Generates a unique hash to identify this version of the server
get_image_tag() {
  head_location=".git/$(awk '{print $2}' <.git/HEAD)"
  head_hash="$(cat "$head_location")"
  if [ -z "$head_hash" ]; then
    # could not read commit hash
    # gen random hash
    head_hash="$(hexdump -n 16 -v -e '/1 "%02X"' -e '/16 "\n"' /dev/urandom)"
  else
    head_hash="gh-${head_hash}"
  fi
  printf "Using hash %s as the docker image tag.\n" "$head_hash"
}

# Builds the server/client and everything else
# Pushes the fresh new images to GCR
# $1 -> docker image name
# $2 -> remote docker image name
# $3 -> docker image tag
docker_build_push() {
  printf "Building docker image and pushing to GCR...\n"
  docker build -f ./project/res/dockerfile_assemble ./project -t "$1"
  docker tag "$1" "${2}:${3}"
  docker tag "$1" "${2}:latest"
  docker push "$2"
  printf "Docker image built and pushed to GCR.\n"
}

# $1 -> remote docker image name + tag for the new version of the server
notify_gcp() {
  printf "Refreshing container of the GCE instance...\n"
  gcloud compute instances update-container "$GCP_INSTANCE" \
    --zone "$GCP_ZONE" \
    --container-image "$1" 
}

# ENTRYPOINT

auth_gcp

schema_migration

# Sets the head_hash variable
get_image_tag

image_name="core-release-img"
gcr_image="${GCP_REPO}/${GCP_PROJECT_ID}/${image_name}"
docker_build_push "$image_name" "$gcr_image" "$head_hash"

notify_gcp "${gcr_image}:${head_hash}"

